{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer đã được lưu tại: tfidf_vectorizer.pkl\n",
      "Shape of TF-IDF matrix: (1101, 5000)\n",
      "LSA Model đã được lưu tại: lsa_model.pkl\n",
      "Shape of LSA-transformed matrix: (1101, 25)\n",
      "Explained variance ratio: 0.1834282961418222\n",
      "Dữ liệu TF-IDF và LSA đã được lưu tại: tfidf_lsa_lyric.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = 'lyric.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Xác định cột chứa lời bài hát\n",
    "lyrics_column = 'lyric'  # Thay bằng tên cột cụ thể nếu khác\n",
    "\n",
    "# Load the Vietnamese stopwords\n",
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Loại bỏ ký tự đặc biệt\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Thay thế ký tự đặc biệt bằng khoảng trắng\n",
    "    text = re.sub(r'\\d+', ' ', text)  # Loại bỏ chữ số\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Loại bỏ khoảng trắng thừa\n",
    "\n",
    "    # 2. Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Loại bỏ stopword\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        words = text.split()\n",
    "        cleaned_text = ' '.join([word for word in words if word not in stop_words])\n",
    "        return cleaned_text\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Áp dụng hàm xử lý lên cột chứa lời bài hát\n",
    "df[lyrics_column] = df[lyrics_column].astype(str).apply(clean_text)\n",
    "df.columns = ['index','name_song','lyric','label']\n",
    "df.drop(['index'], axis=1,inplace=True)\n",
    "\n",
    "processed_path = 'processed_data.csv'\n",
    "df.to_csv(processed_path, index = False)\n",
    "\n",
    "# Chuyển văn bản thành vector TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Bạn có thể điều chỉnh số lượng đặc trưng\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['lyric'])\n",
    "\n",
    "# Lưu TF-IDF vectorizer\n",
    "tfidf_vectorizer_path = 'tfidf_vectorizer.pkl'\n",
    "joblib.dump(tfidf_vectorizer, tfidf_vectorizer_path)\n",
    "print(f\"TF-IDF Vectorizer đã được lưu tại: {tfidf_vectorizer_path}\")\n",
    "\n",
    "# In thông tin TF-IDF\n",
    "print(\"Shape of TF-IDF matrix:\", X_tfidf.shape)\n",
    "\n",
    "# Giảm chiều dữ liệu bằng LSA (SVD)\n",
    "num_topics = 25  # Số lượng chủ đề bạn muốn giữ lại\n",
    "lsa = TruncatedSVD(n_components=num_topics, random_state=42)\n",
    "X_lsa = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "# Lưu mô hình LDA\n",
    "lsa_model_path = 'lsa_model.pkl'\n",
    "joblib.dump(lsa, lsa_model_path)\n",
    "print(f\"LSA Model đã được lưu tại: {lsa_model_path}\")\n",
    "\n",
    "# In thông tin về các thành phần chính\n",
    "print(\"Shape of LSA-transformed matrix:\", X_lsa.shape)\n",
    "print(\"Explained variance ratio:\", lsa.explained_variance_ratio_.sum())\n",
    "\n",
    "# Lưu TF-IDF và LSA vào DataFrame\n",
    "df_tfidf_lsa = pd.DataFrame(X_lsa, columns=[f\"Topic{i+1}\" for i in range(num_topics)])\n",
    "df_tfidf_lsa['label'] = df['label']\n",
    "\n",
    "# Lưu dữ liệu đã xử lý vào file CSV\n",
    "output_path = 'tfidf_lsa_lyric.csv'\n",
    "df_tfidf_lsa.to_csv(output_path, index=False)\n",
    "print(f\"Dữ liệu TF-IDF và LSA đã được lưu tại: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán TF-IDF (Thủ công không dùng sklearn)\n",
    "def compute_tf_idf(corpus):\n",
    "    # Tokenize lời bài hát thành các từ riêng lẻ\n",
    "    tokenized_corpus = [doc.split() for doc in corpus]\n",
    "\n",
    "    # Tính TF (Term Frequency)\n",
    "    term_frequencies = []\n",
    "    for tokens in tokenized_corpus:\n",
    "        tf = {}\n",
    "        for word in tokens:\n",
    "            tf[word] = tf.get(word, 0) + 1\n",
    "        term_frequencies.append(tf)\n",
    "\n",
    "    # Tính DF (Document Frequency)\n",
    "    df = {}\n",
    "    for tf in term_frequencies:\n",
    "        for word in tf.keys():\n",
    "            df[word] = df.get(word, 0) + 1\n",
    "\n",
    "    # Tính IDF (Inverse Document Frequency)\n",
    "    total_docs = len(corpus)\n",
    "    idf = {word: np.log(total_docs / df[word]) for word in df}\n",
    "\n",
    "    # Tính TF-IDF\n",
    "    tf_idf = []\n",
    "    for tf in term_frequencies:\n",
    "        tf_idf_doc = {word: tf[word] * idf[word] for word in tf}\n",
    "        tf_idf.append(tf_idf_doc)\n",
    "\n",
    "    return tf_idf, idf\n",
    "\n",
    "# Tạo ma trận TF-IDF\n",
    "tf_idf_values, idf = compute_tf_idf(df[lyrics_column].astype(str).tolist())\n",
    "\n",
    "# Chuyển đổi TF-IDF thành ma trận dạng số\n",
    "unique_words = list(idf.keys())\n",
    "tf_idf_matrix = []\n",
    "for tf_idf_doc in tf_idf_values:\n",
    "    row = [tf_idf_doc.get(word, 0) for word in unique_words]\n",
    "    tf_idf_matrix.append(row)\n",
    "\n",
    "tf_idf_matrix = np.array(tf_idf_matrix)\n",
    "\n",
    "# Áp dụng LDA thủ công để trích xuất chủ đề\n",
    "def lda(matrix, K, iterations=100, alpha=0.1, beta=0.01):\n",
    "    M, V = matrix.shape  # Số tài liệu và số từ\n",
    "    # Khởi tạo ngẫu nhiên chủ đề cho mỗi từ trong mỗi tài liệu\n",
    "    z = np.random.randint(0, K, size=(M, V))\n",
    "    \n",
    "    # Đếm số lượng từ trong các chủ đề và tài liệu\n",
    "    ndk = np.zeros((M, K))  # Số từ trong mỗi tài liệu thuộc mỗi chủ đề\n",
    "    nkw = np.zeros((K, V))  # Số từ trong mỗi chủ đề\n",
    "    nk = np.zeros(K)        # Tổng số từ trong mỗi chủ đề\n",
    "\n",
    "    for m in range(M):\n",
    "        for v in range(V):\n",
    "            topic = z[m, v]\n",
    "            ndk[m, topic] += matrix[m, v]\n",
    "            nkw[topic, v] += matrix[m, v]\n",
    "            nk[topic] += matrix[m, v]\n",
    "\n",
    "    for it in range(iterations):\n",
    "        for m in range(M):\n",
    "            for v in range(V):\n",
    "                if matrix[m, v] == 0:\n",
    "                    continue\n",
    "\n",
    "                topic = z[m, v]\n",
    "                ndk[m, topic] -= matrix[m, v]\n",
    "                nkw[topic, v] -= matrix[m, v]\n",
    "                nk[topic] -= matrix[m, v]\n",
    "\n",
    "                # Tính xác suất của mỗi chủ đề\n",
    "                p_z = (ndk[m, :] + alpha) * (nkw[:, v] + beta) / (nk + V * beta)\n",
    "                p_z /= p_z.sum()\n",
    "\n",
    "                # Lấy chủ đề mới theo phân phối p_z\n",
    "                new_topic = np.random.choice(K, p=p_z)\n",
    "                z[m, v] = new_topic\n",
    "\n",
    "                ndk[m, new_topic] += matrix[m, v]\n",
    "                nkw[new_topic, v] += matrix[m, v]\n",
    "                nk[new_topic] += matrix[m, v]\n",
    "\n",
    "    return ndk, nkw\n",
    "\n",
    "K = 10  # Số chủ đề\n",
    "ndk, nkw = lda(tf_idf_matrix, K)\n",
    "\n",
    "# Tạo DataFrame với các chủ đề cho mỗi tài liệu\n",
    "topic_columns = [f'topic_{i+1}' for i in range(K)]\n",
    "df_topics = pd.DataFrame(ndk, columns=topic_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def stratified_train_test_split(data, label_col, test_size=0.2, random_state=None):\n",
    "    # Kiểm tra sự tồn tại của cột nhãn\n",
    "    if label_col not in data.columns:\n",
    "        raise ValueError(f\"Cột '{label_col}' không tồn tại trong dữ liệu.\")\n",
    "    \n",
    "    # Thiết lập giá trị random seed nếu cần\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Lấy danh sách các nhãn và tỷ lệ của chúng\n",
    "    label_counts = data[label_col].value_counts(normalize=True)\n",
    "    \n",
    "    # Tạo danh sách các chỉ số của tập dữ liệu\n",
    "    indices = data.index.tolist()\n",
    "    \n",
    "    # Khởi tạo danh sách cho các chỉ số của train và test\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Chia dữ liệu theo tỷ lệ nhãn\n",
    "    for label, proportion in label_counts.items():\n",
    "        # Lấy các chỉ số của mẫu có nhãn tương ứng\n",
    "        label_indices = data[data[label_col] == label].index.tolist()\n",
    "        \n",
    "        # Xác định số lượng mẫu cần thiết cho tập test\n",
    "        test_count = int(len(label_indices) * test_size)\n",
    "        \n",
    "        # Xáo trộn chỉ số của nhãn này\n",
    "        np.random.shuffle(label_indices)\n",
    "        \n",
    "        # Tách ra tập train và test\n",
    "        test_indices += label_indices[:test_count]\n",
    "        train_indices += label_indices[test_count:]\n",
    "    \n",
    "    # Lấy tập dữ liệu train và test\n",
    "    train_data = data.loc[train_indices]\n",
    "    test_data = data.loc[test_indices]\n",
    "    \n",
    "    # Lưu dữ liệu ra file CSV\n",
    "    train_data.to_csv('train_data.csv', index=False)\n",
    "    test_data.to_csv('test_data.csv', index=False)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = 'tfidf_lsa_lyric.csv'  # File chứa dữ liệu đầu vào\n",
    "\n",
    "try:\n",
    "    df_tfidf_lsa = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File không tồn tại. Vui lòng kiểm tra đường dẫn.\")\n",
    "    exit()\n",
    "\n",
    "# Tách dữ liệu thành train và test\n",
    "train_df, test_df = stratified_train_test_split(\n",
    "    data=df_tfidf_lsa,\n",
    "    label_col='label',  # Đảm bảo cột 'label' đã tồn tại\n",
    "    test_size=0.2,\n",
    "    random_state=48\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n",
      "Best parameters found: {'bootstrap': True, 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best accuracy score: 0.6326530612244898\n",
      "Test Accuracy: 0.6986301369863014\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        buồn       0.73      0.80      0.76        83\n",
      "         vui       0.69      0.74      0.71        61\n",
      "  yêu thương       0.67      0.56      0.61        75\n",
      "\n",
      "    accuracy                           0.70       219\n",
      "   macro avg       0.69      0.70      0.69       219\n",
      "weighted avg       0.70      0.70      0.69       219\n",
      "\n",
      "Mô hình tốt nhất đã được lưu tại: best_randomforest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "data_train = pd.read_csv('train_data.csv')\n",
    "data_test = pd.read_csv('test_data.csv')\n",
    "X_train = data_train.drop(columns=['label'])\n",
    "X_test = data_test.drop(columns=['label'])\n",
    "\n",
    "y_train = data_train['label']\n",
    "y_test = data_test['label']\n",
    "\n",
    "# Thiết lập tham số cho GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Thiết lập GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Huấn luyện mô hình grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In kết quả tốt nhất\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best accuracy score:\", grid_search.best_score_)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra với mô hình tốt nhất\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Lưu mô hình tốt nhất nếu cần thiết\n",
    "import joblib\n",
    "model_path = 'best_randomforest_model.pkl'\n",
    "joblib.dump(best_rf, model_path)\n",
    "print(f\"Mô hình tốt nhất đã được lưu tại: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.730593607305936\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        buồn       0.73      0.86      0.79        83\n",
      "         vui       0.72      0.75      0.74        61\n",
      "  yêu thương       0.74      0.57      0.65        75\n",
      "\n",
      "    accuracy                           0.73       219\n",
      "   macro avg       0.73      0.73      0.72       219\n",
      "weighted avg       0.73      0.73      0.73       219\n",
      "\n",
      "Mô hình đã được lưu tại: random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data_train = pd.read_csv('train_data.csv')\n",
    "data_test = pd.read_csv('test_data.csv')\n",
    "X_train = data_train.drop(columns=['label'])\n",
    "X_test = data_test.drop(columns=['label'])\n",
    "\n",
    "y_train = data_train['label']\n",
    "y_test = data_test['label']\n",
    "\n",
    "\n",
    "# Huấn luyện mô hình Random Forest\n",
    "rf_model = RandomForestClassifier(bootstrap= True, max_depth= 10, min_samples_leaf= 4, min_samples_split= 10, n_estimators= 200, random_state=44)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Lưu mô hình nếu cần thiết\n",
    "import joblib\n",
    "model_path = 'random_forest_model.pkl'\n",
    "joblib.dump(rf_model, model_path)\n",
    "print(f\"Mô hình đã được lưu tại: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được tải thành công.\n",
      "Shape of TF-IDF matrix: (1, 5000)\n",
      "(1, 25)\n",
      "Cảm xúc dự đoán của bài hát : vui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Load the Vietnamese stopwords\n",
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "def clean_text(text):\n",
    "    # 1. Loại bỏ ký tự đặc biệt\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Thay thế ký tự đặc biệt bằng khoảng trắng\n",
    "    text = re.sub(r'\\d+', ' ', text)  # Loại bỏ chữ số\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Loại bỏ khoảng trắng thừa\n",
    "\n",
    "    # 2. Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Loại bỏ stopword\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        words = text.split()\n",
    "        cleaned_text = ' '.join([word for word in words if word not in stop_words])\n",
    "        return cleaned_text\n",
    "    return ' '.join(words)\n",
    "model_path = 'random_forest_model.pkl'\n",
    "best_rf = joblib.load(model_path)\n",
    "print(\"Mô hình đã được tải thành công.\")\n",
    "\n",
    "    \n",
    "df_test = pd.DataFrame([[1001,'Buồn','''anh hẹn em pickleball''']], columns=['index','name_song', 'lyric'])\n",
    "\n",
    "df_test['lyric'] = df_test['lyric'].astype(str).apply(clean_text)\n",
    "df_test.columns = ['index','name_song','lyric']\n",
    "df_test.head()\n",
    "\n",
    "\n",
    "# Chuyển văn bản thành vector TF-IDF\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "new_tfidf = tfidf_vectorizer.transform(df_test['lyric'])\n",
    "\n",
    "# In thông tin TF-IDF\n",
    "print(\"Shape of TF-IDF matrix:\", new_tfidf.shape)\n",
    "\n",
    "# Giảm chiều dữ liệu bằng LSA (SVD)\n",
    "lda_model = joblib.load('lsa_model.pkl')\n",
    "\n",
    "new_lda = lda_model.transform(new_tfidf)\n",
    "print(new_lda.shape)\n",
    "\n",
    "predicted_label = best_rf.predict(new_lda)\n",
    "\n",
    "print(f\"Cảm xúc dự đoán của bài hát :\", predicted_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
