{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer đã được lưu tại: tfidf_vectorizer.pkl\n",
      "Shape of TF-IDF matrix: (1101, 5000)\n",
      "LSA Model đã được lưu tại: lsa_model.pkl\n",
      "Shape of LSA-transformed matrix: (1101, 25)\n",
      "Explained variance ratio: 0.1834282961418222\n",
      "Dữ liệu TF-IDF và LSA đã được lưu tại: tfidf_lsa_lyric.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# Read data from csv file\n",
    "file_path = '../data/lyric.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Lyrics data columns\n",
    "lyrics_column = 'lyric'  \n",
    "\n",
    "# Load the Vietnamese stopwords\n",
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Delete \n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Replace by whitespace\n",
    "    text = re.sub(r'\\d+', ' ', text)  # Delete numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Delete whitespaces\n",
    "\n",
    "    # 2. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Delete stopword\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        words = text.split()\n",
    "        cleaned_text = ' '.join([word for word in words if word not in stop_words])\n",
    "        return cleaned_text\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the process function to the data\n",
    "df[lyrics_column] = df[lyrics_column].astype(str).apply(clean_text)\n",
    "df.columns = ['index','name_song','lyric','label']\n",
    "df.drop(['index'], axis=1,inplace=True)\n",
    "# Export processed data\n",
    "processed_path = '../data/processed_data.csv'\n",
    "df.to_csv(processed_path, index = False)\n",
    "\n",
    "# Vector TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  \n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['lyric'])\n",
    "\n",
    "# Save TF-IDF vectorizer\n",
    "tfidf_vectorizer_path = '../model/tfidf_vectorizer.pkl'\n",
    "joblib.dump(tfidf_vectorizer, tfidf_vectorizer_path)\n",
    "print(f\"TF-IDF Vectorizer đã được lưu tại: {tfidf_vectorizer_path}\")\n",
    "\n",
    "# Print TF-IDF shape\n",
    "print(\"Shape of TF-IDF matrix:\", X_tfidf.shape)\n",
    "\n",
    "# LSA (SVD)\n",
    "num_topics = 25  # number of topics\n",
    "lsa = TruncatedSVD(n_components=num_topics, random_state=42)\n",
    "X_lsa = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "# save the lsa model\n",
    "lsa_model_path = '../model/lsa_model.pkl'\n",
    "joblib.dump(lsa, lsa_model_path)\n",
    "print(f\"LSA Model đã được lưu tại: {lsa_model_path}\")\n",
    "\n",
    "print(\"Shape of LSA-transformed matrix:\", X_lsa.shape)\n",
    "print(\"Explained variance ratio:\", lsa.explained_variance_ratio_.sum())\n",
    "\n",
    "# Apply TF-IDF and LSA to DataFrame\n",
    "df_tfidf_lsa = pd.DataFrame(X_lsa, columns=[f\"Topic{i+1}\" for i in range(num_topics)])\n",
    "df_tfidf_lsa['label'] = df['label']\n",
    "\n",
    "# Save the results\n",
    "output_path = '../data/tfidf_lsa_lyric.csv'\n",
    "df_tfidf_lsa.to_csv(output_path, index=False)\n",
    "print(f\"Dữ liệu TF-IDF và LSA đã được lưu tại: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def stratified_train_test_split(data, label_col, test_size=0.2, random_state=None):\n",
    "    # Check if the label column exists\n",
    "    if label_col not in data.columns:\n",
    "        raise ValueError(f\"Column '{label_col}' does not exist in the data.\")\n",
    "    \n",
    "    # Set random seed if needed\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Get the list of labels and their proportions\n",
    "    label_counts = data[label_col].value_counts(normalize=True)\n",
    "    \n",
    "    # Create a list of indices for the dataset\n",
    "    indices = data.index.tolist()\n",
    "    \n",
    "    # Initialize lists for the train and test indices\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Split the data based on label proportions\n",
    "    for label, proportion in label_counts.items():\n",
    "        # Get the indices of samples with the corresponding label\n",
    "        label_indices = data[data[label_col] == label].index.tolist()\n",
    "        \n",
    "        # Determine the number of samples required for the test set\n",
    "        test_count = int(len(label_indices) * test_size)\n",
    "        \n",
    "        # Shuffle the indices of this label\n",
    "        np.random.shuffle(label_indices)\n",
    "        \n",
    "        # Split into train and test sets\n",
    "        test_indices += label_indices[:test_count]\n",
    "        train_indices += label_indices[test_count:]\n",
    "    \n",
    "    # Get the train and test datasets\n",
    "    train_data = data.loc[train_indices]\n",
    "    test_data = data.loc[test_indices]\n",
    "    \n",
    "    # Save the datasets to CSV files\n",
    "    train_data.to_csv('../data/train_data.csv', index=False)\n",
    "    test_data.to_csv('../data/test_data.csv', index=False)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Read data from a CSV file\n",
    "file_path = '../data/tfidf_lsa_lyric.csv'  # File containing the input data\n",
    "\n",
    "try:\n",
    "    df_tfidf_lsa = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File does not exist. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "# Split the data into train and test\n",
    "train_df, test_df = stratified_train_test_split(\n",
    "    data=df_tfidf_lsa,\n",
    "    label_col='label',  # Ensure the 'label' column exists\n",
    "    test_size=0.2,\n",
    "    random_state=48\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n",
      "Best parameters found: {'bootstrap': True, 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best accuracy score: 0.6326530612244898\n",
      "Test Accuracy: 0.6986301369863014\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        buồn       0.73      0.80      0.76        83\n",
      "         vui       0.69      0.74      0.71        61\n",
      "  yêu thương       0.67      0.56      0.61        75\n",
      "\n",
      "    accuracy                           0.70       219\n",
      "   macro avg       0.69      0.70      0.69       219\n",
      "weighted avg       0.70      0.70      0.69       219\n",
      "\n",
      "Mô hình tốt nhất đã được lưu tại: best_randomforest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Read training and test data\n",
    "data_train = pd.read_csv('../data/train_data.csv')\n",
    "data_test = pd.read_csv('../data/test_data.csv')\n",
    "X_train = data_train.drop(columns=['label'])\n",
    "X_test = data_test.drop(columns=['label'])\n",
    "\n",
    "y_train = data_train['label']\n",
    "y_test = data_test['label']\n",
    "\n",
    "# Set parameters for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Train the model with grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best accuracy score:\", grid_search.best_score_)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the best model if needed\n",
    "import joblib\n",
    "model_path = '../model/best_randomforest_model.pkl'\n",
    "joblib.dump(best_rf, model_path)\n",
    "print(f\"The best model has been saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.730593607305936\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        buồn       0.73      0.86      0.79        83\n",
      "         vui       0.72      0.75      0.74        61\n",
      "  yêu thương       0.74      0.57      0.65        75\n",
      "\n",
      "    accuracy                           0.73       219\n",
      "   macro avg       0.73      0.73      0.72       219\n",
      "weighted avg       0.73      0.73      0.73       219\n",
      "\n",
      "Mô hình đã được lưu tại: random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Read training and test data\n",
    "data_train = pd.read_csv('../data/train_data.csv')\n",
    "data_test = pd.read_csv('../data/test_data.csv')\n",
    "X_train = data_train.drop(columns=['label'])\n",
    "X_test = data_test.drop(columns=['label'])\n",
    "\n",
    "y_train = data_train['label']\n",
    "y_test = data_test['label']\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(bootstrap=True, max_depth=10, min_samples_leaf=4, \n",
    "                                  min_samples_split=10, n_estimators=200, random_state=44)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model if needed\n",
    "import joblib\n",
    "model_path = '../model/random_forest_model.pkl'\n",
    "joblib.dump(rf_model, model_path)\n",
    "print(f\"The model has been saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được tải thành công.\n",
      "Shape of TF-IDF matrix: (1, 5000)\n",
      "(1, 25)\n",
      "Cảm xúc dự đoán của bài hát : vui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Load the Vietnamese stopwords\n",
    "with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "def clean_text(text):\n",
    "    # 1. Loại bỏ ký tự đặc biệt\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Thay thế ký tự đặc biệt bằng khoảng trắng\n",
    "    text = re.sub(r'\\d+', ' ', text)  # Loại bỏ chữ số\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Loại bỏ khoảng trắng thừa\n",
    "\n",
    "    # 2. Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Loại bỏ stopword\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        words = text.split()\n",
    "        cleaned_text = ' '.join([word for word in words if word not in stop_words])\n",
    "        return cleaned_text\n",
    "    return ' '.join(words)\n",
    "model_path = '../model/random_forest_model.pkl'\n",
    "best_rf = joblib.load(model_path)\n",
    "print(\"Mô hình đã được tải thành công.\")\n",
    "\n",
    "    \n",
    "df_test = pd.DataFrame([[1001,'Buồn','''anh hẹn em pickleball''']], columns=['index','name_song', 'lyric'])\n",
    "\n",
    "df_test['lyric'] = df_test['lyric'].astype(str).apply(clean_text)\n",
    "df_test.columns = ['index','name_song','lyric']\n",
    "df_test.head()\n",
    "\n",
    "\n",
    "# Chuyển văn bản thành vector TF-IDF\n",
    "tfidf_vectorizer = joblib.load('../model/fidf_vectorizer.pkl')\n",
    "\n",
    "new_tfidf = tfidf_vectorizer.transform(df_test['lyric'])\n",
    "\n",
    "# In thông tin TF-IDF\n",
    "print(\"Shape of TF-IDF matrix:\", new_tfidf.shape)\n",
    "\n",
    "# Giảm chiều dữ liệu bằng LSA (SVD)\n",
    "lda_model = joblib.load('../model/lsa_model.pkl')\n",
    "\n",
    "new_lda = lda_model.transform(new_tfidf)\n",
    "print(new_lda.shape)\n",
    "\n",
    "predicted_label = best_rf.predict(new_lda)\n",
    "\n",
    "print(f\"Cảm xúc dự đoán của bài hát :\", predicted_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
